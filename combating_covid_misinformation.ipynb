{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a COVID news classifier using Amazon Comprehend\n",
    "\n",
    "> *This notebook has been tested with the `Python 3 (Data Science)` Kernel in SageMaker Studio.*\n",
    "\n",
    "[Amazon Comprehend](https://aws.amazon.com/comprehend/) is a natural language processing (NLP) service that uses machine learning to analyze text.\n",
    "\n",
    "In this example notebook, we'll demonstrate how you can build and use a custom text classifier using an example news dataset. You can read more about how this works in the [Custom Classification section](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) of the [Amazon Comprehend Developer Guide](https://docs.aws.amazon.com/comprehend/latest/dg/).\n",
    "\n",
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.exceptions import WaiterError\n",
    "from botocore.waiter import create_waiter_with_client, WaiterModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Session and Get Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start using Amazon Comprehend, ensure that your SageMaker Studio Execution role has the permissions to access Amazon S3 and Amazon Comprehend. Read more about the execution role [here](https://docs.aws.amazon.com/sagemaker/latest/dg/security_iam_service-with-iam.html).\n",
    "\n",
    "Refer to this [link](https://docs.aws.amazon.com/comprehend/latest/dg/access-control-managing-permissions.html) for more information regarding managing access to Amazon Comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get execution role. Search for the execution role in the IAM console to modify permissions.\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the S3 Bucket associated with this SageMaker Studio session. We will use this bucket to store and retrieve data.\n",
    "bucket = sess.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, examine and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses data from various social media platforms, manually labeled as either 'fake' or 'real' news. It was initially published in a [paper](https://link.springer.com/chapter/10.1007/978-3-030-73696-5_3) and used in this [competition](https://competitions.codalab.org/competitions/26655). \n",
    "#### Dataset Reference:\n",
    "Patwa P. et al. (2021) Fighting an Infodemic: COVID-19 Fake News Dataset. In: Chakraborty T., Shu K., Bernard H.R., Liu H., Akhtar M.S. (eds) Combating Online Hostile Posts in Regional Languages during Emergency Situation. CONSTRAINT 2021. Communications in Computer and Information Science, vol 1402. Springer, Cham. https://doi.org/10.1007/978-3-030-73696-5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/diptamath/covid_fake_news/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine the source training and validation datasets for Amazon Comprehend, and allow it to split an internal validation set automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = pd.read_csv(\"covid_fake_news/data/Constraint_Train.csv\")\n",
    "df_val_data = pd.read_csv(\"covid_fake_news/data/Constraint_Val.csv\")\n",
    "df_data = pd.concat([df_train_data,df_val_data], ignore_index=True)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the distribution of data\n",
    "\n",
    "If the data is skewed, we will need to adjust the proportion of training data with 'real' and 'fake' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle data\n",
    "\n",
    "The data is not highly skewed, so we will simply randomize it before loading it in for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sample(frac=1, random_state=1)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to the format that Amazon Comprehend expects for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about creating a classifier on Amazon Comprehend [here](https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-console-classifier.html).\n",
    "\n",
    "For training, the Comprehend expects the following:\n",
    "1. File must contain only 2 columns: one label and one text per line\n",
    "2. No header\n",
    "3. Format UTF-8, line separator \"\\n\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the indices and headers before we upload the file to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_data[[\"label\", \"tweet\"]]\n",
    "df_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output data to a CSV file and upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data/processed-data/\n",
    "path = \"data/processed-data/processed.csv\"\n",
    "prefix = \"COVIDcomprehend\"\n",
    "# Output to CSV file\n",
    "df_out.to_csv(path, index=False, header=False)\n",
    "# Upload to S3 Bucket\n",
    "processed_data_s3 = sess.upload_data(\n",
    "    path=path,\n",
    "    key_prefix=prefix,\n",
    "    bucket=bucket \n",
    ")\n",
    "print(\"Training data has been uploaded to S3.\")\n",
    "print(\"Location:\", processed_data_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IAM role and attach policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To authorize Amazon Comprehend to interact with your S3 buckets, you must grant Amazon Comprehend access to it by creating an IAM role in your account with the relevant permissions and trust policies. Read more about it [here](https://docs.aws.amazon.com/comprehend/latest/dg/access-control-overview.html). To better understand how to manage S3 permissions, please refer to this [documentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-access-control.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_role_name = \"ComprehendRole\"\n",
    "\n",
    "# Instantiate Boto3 SDK\n",
    "client_iam = boto3.client(\"iam\")\n",
    "\n",
    "# Allow Comprehend to assume this role\n",
    "assume_role_policy_document = json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"comprehend.amazonaws.com\",\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        },\n",
    "    ],\n",
    "})\n",
    "\n",
    "# Create IAM Role if it does not exist\n",
    "try:\n",
    "    client_iam.get_role(RoleName=comprehend_role_name)\n",
    "    print(\"Role already exists.\")\n",
    "except:\n",
    "    response = client_iam.create_role(\n",
    "        RoleName=comprehend_role_name,\n",
    "        AssumeRolePolicyDocument=assume_role_policy_document,\n",
    "    )\n",
    "    print(\"Created a new role.\")\n",
    "    print(\"Comprehend Role ID:\", response[\"Role\"][\"RoleId\"])\n",
    "    \n",
    "comprehend_role_arn = client_iam.get_role(RoleName=comprehend_role_name)[\"Role\"][\"Arn\"]\n",
    "print(\"Comprehend Role ARN:\", comprehend_role_arn)\n",
    "\n",
    "# Attach permission policy to IAM role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "\n",
    "print(\"Attaching IAM role policy\")\n",
    "attach_response = client_iam.attach_role_policy(\n",
    "    RoleName=comprehend_role_name,\n",
    "    PolicyArn=policy_arn,\n",
    ")\n",
    "sleep(60)\n",
    "print(\"IAM policy is attached.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Classifier and Commence Training\n",
    "Read about training a classifier [here](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification-training.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_classifier_name = \"COVIDInfoClassifer\"\n",
    "version_name = \"v0\"\n",
    "\n",
    "# Instantiate Boto3 SDK\n",
    "client_comp = boto3.client(\"comprehend\")\n",
    "\n",
    "# Create a document classifier\n",
    "create_response = client_comp.create_document_classifier(\n",
    "    InputDataConfig={ \"S3Uri\": processed_data_s3 },\n",
    "    DataAccessRoleArn=comprehend_role_arn,\n",
    "    DocumentClassifierName=doc_classifier_name,\n",
    "    VersionName=version_name,\n",
    "    LanguageCode=\"en\",\n",
    ")\n",
    "doc_classifier_arn = create_response[\"DocumentClassifierArn\"]\n",
    "print(\"Create response:\", create_response[\"ResponseMetadata\"][\"HTTPStatusCode\"])\n",
    "print(\"Classifier ARN:\", doc_classifier_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_classifier = client_comp.describe_document_classifier(\n",
    "    DocumentClassifierArn=doc_classifier_arn,\n",
    ")\n",
    "try:\n",
    "    classifier_initial_status = describe_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(\"Describe classifier response:\", classifier_initial_status)\n",
    "except:\n",
    "    print(\"Status error\")\n",
    "# Creating Waiter to manage waiting for training to complete\n",
    "classifier_trained_waiter = create_waiter_with_client(\n",
    "    waiter_name=\"ClassifierTrainedWaiter\",\n",
    "    waiter_model=WaiterModel({\n",
    "        \"version\": 2,\n",
    "        \"waiters\": {\n",
    "            \"ClassifierTrainedWaiter\": {\n",
    "                \"operation\": \"DescribeDocumentClassifier\",\n",
    "                \"delay\": 30,\n",
    "                \"maxAttempts\": 300,\n",
    "                \"acceptors\": [\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"TRAINED\",\n",
    "                        \"argument\": \"DocumentClassifierProperties.Status\",\n",
    "                        \"state\": \"success\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"SUBMITTED\",\n",
    "                        \"argument\": \"DocumentClassifierProperties.Status\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"TRAINING\",\n",
    "                        \"argument\": \"DocumentClassifierProperties.Status\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"IN_ERROR\",\n",
    "                        \"argument\": \"DocumentClassifierProperties.Status\",\n",
    "                        \"state\": \"failure\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"STOPPED\",\n",
    "                        \"argument\": \"DocumentClassifierProperties.Status\",\n",
    "                        \"state\": \"failure\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    }),\n",
    "    client=client_comp,\n",
    ")\n",
    "try:\n",
    "    print(\"Waiting for training...\")\n",
    "    classifier_trained_waiter.wait(DocumentClassifierArn=doc_classifier_arn)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "except WaiterError as e:\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your classifier has been created, go to the AWS Console for Comprehend to check out your classifier. \n",
    "\n",
    "Read more about model performance [here](https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy your classifier to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{doc_classifier_name}-{version_name}-endpoint\"\n",
    "# Create endpoint\n",
    "create_endpoint_resp = client_comp.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ModelArn=doc_classifier_arn,\n",
    "    DesiredInferenceUnits=1\n",
    ")\n",
    "endpoint_arn = create_endpoint_resp[\"EndpointArn\"]\n",
    "print(\"Created endpoint.\")\n",
    "print(\"Endpoint ARN\", endpoint_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_endpoint = client_comp.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "try:\n",
    "    endpoint_initial_status = describe_endpoint[\"EndpointProperties\"][\"Status\"]\n",
    "    print(\"Describe endpoint response:\", endpoint_initial_status)\n",
    "except:\n",
    "    print(\"Status error\")\n",
    "# Creating Waiter to manage waiting for endpoint to create\n",
    "endpoint_creation_waiter = create_waiter_with_client(\n",
    "    waiter_name=\"EndpointCreationWaiter\",\n",
    "    waiter_model=WaiterModel({\n",
    "        \"version\": 2,\n",
    "        \"waiters\": {\n",
    "            \"EndpointCreationWaiter\": {\n",
    "                \"operation\": \"DescribeEndpoint\",\n",
    "                \"delay\": 30,\n",
    "                \"maxAttempts\": 100,\n",
    "                \"acceptors\": [\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"IN_SERVICE\",\n",
    "                        \"argument\": \"EndpointProperties.Status\",\n",
    "                        \"state\": \"success\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"UPDATING\",\n",
    "                        \"argument\": \"EndpointProperties.Status\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"CREATING\",\n",
    "                        \"argument\": \"EndpointProperties.Status\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"FAILED\",\n",
    "                        \"argument\": \"EndpointProperties.Status\",\n",
    "                        \"state\": \"failure\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    }),\n",
    "    client=client_comp,\n",
    ")\n",
    "try:\n",
    "    print(\"Waiting for endpoint...\")\n",
    "    endpoint_creation_waiter.wait(EndpointArn=endpoint_arn)\n",
    "    print(\"ENDPOINT CREATED\")\n",
    "except WaiterError as e:\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the labeled test data to run some predictions and obtain some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine test data\n",
    "df_test = pd.read_csv(\"covid_fake_news/data/english_test_with_labels.csv\")\n",
    "df_test = df_test[[\"label\", \"tweet\"]]\n",
    "df_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into two arrays, where X_test contains tweets and Y_test contains labels\n",
    "X_test = df_test[\"tweet\"].values\n",
    "Y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating real-time predictions using Comprehend's endpoint\n",
    "Read more about real time analysis using an endpoint [here](https://docs.aws.amazon.com/comprehend/latest/dg/cc-real-time-analysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test[0]\n",
    "print(test)\n",
    "client_comp.classify_document(Text=test, EndpointArn=endpoint_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = X_test[1]\n",
    "print(test1)\n",
    "client_comp.classify_document(Text=test1, EndpointArn=endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an asynchronous classification job\n",
    "We will create a job to perform predictions for the entire test dataset. \n",
    "\n",
    "Read more about the data requirements and job inputs [here](https://docs.aws.amazon.com/comprehend/latest/dg/how-class-run.html).\n",
    "\n",
    "Comprehend's asynchronous classification job expects that for multiple documents in a single text file, each document is separated by a single line break.\n",
    "\n",
    "We will remove all line breaks from the original dataset, then add a line feed character at the end of every document in the text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to the format that Amazon Comprehend expects for asynchronous classification jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/processed-data/test.txt\"\n",
    "test_prefix = \"COVIDcomprehend\"\n",
    "# Remove all line breaks\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda s: s.replace(\"\\n\", \"\"))\n",
    "# Output to text file while separating each document with a line feed character '\\n'\n",
    "df_test[\"tweet\"].to_csv(test_path, index=False, header=False, line_terminator=\"\\n\")\n",
    "# Upload to S3 Bucket\n",
    "test_data_s3 = sess.upload_data(\n",
    "    path=test_path,\n",
    "    key_prefix=test_prefix,\n",
    "    bucket=bucket,\n",
    ")\n",
    "print(\"Test data has been uploaded to S3.\")\n",
    "print(\"Location:\", test_data_s3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start classification job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"{doc_classifier_name}-{version_name}-Job\"\n",
    "test_data_output=f\"s3://{bucket}/{test_prefix}/{job_name}\"\n",
    "# Create classification job\n",
    "create_job_desc = client_comp.start_document_classification_job(\n",
    "    JobName=job_name,\n",
    "    DocumentClassifierArn=doc_classifier_arn,\n",
    "    InputDataConfig={\n",
    "        \"S3Uri\": test_data_s3,\n",
    "        \"InputFormat\": \"ONE_DOC_PER_LINE\",\n",
    "    },\n",
    "    OutputDataConfig={ \"S3Uri\": test_data_output },\n",
    "    DataAccessRoleArn=comprehend_role_arn,\n",
    ")\n",
    "job_id=create_job_desc[\"JobId\"]\n",
    "print(\"Started classification job.\")\n",
    "print(\"Job ID is\", job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_job=client_comp.describe_document_classification_job(JobId=job_id)\n",
    "try:\n",
    "    job_initial_status=describe_job[\"DocumentClassificationJobProperties\"][\"JobStatus\"]\n",
    "    print(\"Describe classification job response:\", job_initial_status)\n",
    "except:\n",
    "    print(\"Status error\")\n",
    "# Creating Waiter to manage waiting for job to complete\n",
    "job_waiter = create_waiter_with_client(\n",
    "    waiter_name=\"JobWaiter\",\n",
    "    waiter_model=WaiterModel({\n",
    "        \"version\": 2,\n",
    "        \"waiters\": {\n",
    "            \"JobWaiter\": {\n",
    "                \"operation\": \"DescribeDocumentClassificationJob\",\n",
    "                \"delay\": 30,\n",
    "                \"maxAttempts\": 300,\n",
    "                \"acceptors\": [\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"COMPLETED\",\n",
    "                        \"argument\": \"DocumentClassificationJobProperties.JobStatus\",\n",
    "                        \"state\": \"success\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"SUBMITTED\",\n",
    "                        \"argument\": \"DocumentClassificationJobProperties.JobStatus\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"IN_PROGRESS\",\n",
    "                        \"argument\": \"DocumentClassificationJobProperties.JobStatus\",\n",
    "                        \"state\": \"retry\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"FAILED\",\n",
    "                        \"argument\": \"DocumentClassificationJobProperties.JobStatus\",\n",
    "                        \"state\": \"failure\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"matcher\": \"path\",\n",
    "                        \"expected\": \"STOPPED\",\n",
    "                        \"argument\": \"DocumentClassificationJobProperties.JobStatus\",\n",
    "                        \"state\": \"failure\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    }),\n",
    "    client=client_comp,\n",
    ")\n",
    "try:\n",
    "    print(\"Waiting for classification job...\")\n",
    "    job_waiter.wait(JobId=job_id)\n",
    "    print(f\"JOB COMPLETE: ID {job_id}\")\n",
    "    complete_job = job_id\n",
    "except WaiterError as e:\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the results of the classification job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = describe_job[\"DocumentClassificationJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "print(\"Results from Job ID\", job_id)\n",
    "batch_output_bucket, _, batch_output_file = batch_output[len(\"s3://\"):].partition(\"/\")\n",
    "\n",
    "# Instantiate Boto3 SDK\n",
    "s3_client = boto3.client(\"s3\")\n",
    "# Download output file containing predictions\n",
    "s3_client.download_file(bucket, batch_output_file, \"data/output.tar.gz\")\n",
    "# Unzip\n",
    "!cd data && tar -xvf output.tar.gz\n",
    "# Load predictions\n",
    "df_batch = pd.read_json(\"data/predictions.jsonl\", lines=True)\n",
    "preds = df_batch[\"Classes\"]\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, iterate through predictions to combine with and compare against original test data, and construct a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_pred = pd.DataFrame({\n",
    "    \"tweet\": df_test[\"tweet\"],\n",
    "    \"label\": df_test[\"label\"],\n",
    "    \"label_pred\": preds.apply(lambda p: p[0][\"Name\"]),\n",
    "    \"score_pred\": preds.apply(lambda p: p[0][\"Score\"]),\n",
    "})\n",
    "df_data_pred[\"label vs label pred\"] = np.where(\n",
    "    df_data_pred[\"label\"] == df_data_pred[\"label_pred\"],\n",
    "    \"same\",\n",
    "    \"different\",\n",
    ")\n",
    "df_data_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    class_names_list=[\"Class1\", \"Class2\"],\n",
    "    axis=None,\n",
    "    title=\"Confusion matrix\",\n",
    "    plot_style=\"ggplot\",\n",
    "    colormap=plt.cm.Blues,\n",
    "):\n",
    "\n",
    "    if axis is None:  # for standalone plot\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    else:  # for plots inside a subplot\n",
    "        ax = axis\n",
    "\n",
    "    plt.style.use(plot_style)\n",
    "\n",
    "    # normalizing matrix to [0,100%]\n",
    "    confusion_matrix_norm = (\n",
    "        confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "    confusion_matrix_norm = np.round(100 * confusion_matrix_norm, 2)\n",
    "\n",
    "    ax.imshow(\n",
    "        confusion_matrix_norm,\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=colormap,\n",
    "        vmin=0,  # to make sure colors are scaled between [0,100%]\n",
    "        vmax=100,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    tick_marks = np.arange(len(class_names_list))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(class_names_list, rotation=0)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(class_names_list)\n",
    "    \n",
    "    for i, j in itertools.product(\n",
    "        range(confusion_matrix.shape[0]),\n",
    "        range(confusion_matrix.shape[1])\n",
    "    ):\n",
    "        ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            str(confusion_matrix[i, j])+'\\n('+str(confusion_matrix_norm[i,j])+'%)',\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if confusion_matrix_norm[i, j] > 50 else \"black\"\n",
    "        )\n",
    "\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.grid(False)\n",
    "    \n",
    "    if axis is None:  # for standalone plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = df_data_pred[\"label\"]\n",
    "y_pred = df_data_pred[\"label_pred\"]\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    metrics.confusion_matrix(y_real, y_pred),\n",
    "    class_names_list=[\"Fake\", \"Real\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did we identify what's fake? We will calculate performance scores and plot some graphs to examine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take note that \"fake\" would be \"positive\" with a label of 1\n",
    "metrics_ACC = metrics.accuracy_score(y_real, y_pred)\n",
    "metrics_P_fake = metrics.precision_score(y_real, y_pred, average=\"binary\", pos_label=\"fake\")\n",
    "metrics_R_fake = metrics.recall_score(y_real, y_pred, average=\"binary\", pos_label=\"fake\")\n",
    "metrics_f1 = metrics.f1_score(y_real, y_pred, average=\"binary\", pos_label=\"fake\")\n",
    "print(\n",
    "    \"Accuracy\", metrics_ACC,\n",
    "    \"Precision (fake)\", metrics_P_fake,\n",
    "    \"Recall (fake)\", metrics_R_fake,\n",
    "    \"F1 score\", metrics_f1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(\n",
    "    y_real,\n",
    "    y_predict,\n",
    "    axis=None,\n",
    "    plot_style=\"ggplot\",\n",
    "):\n",
    "    \"\"\"Plot a nice precision/recall curve for a binary classification model\"\"\"\n",
    "\n",
    "    if axis is None:  # for standalone plot\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    else:  # for plots inside a subplot\n",
    "        ax = axis\n",
    "\n",
    "    plt.style.use(plot_style)\n",
    "\n",
    "    metrics_P, metrics_R, _ = metrics.precision_recall_curve(y_real, y_predict)\n",
    "    metrics_AP = metrics.average_precision_score(y_real, y_predict)\n",
    "\n",
    "    ax.set_aspect(aspect=0.95)\n",
    "    ax.step(metrics_R, metrics_P, color=\"b\", where=\"post\", linewidth=0.7)\n",
    "    ax.fill_between(metrics_R, metrics_P, step=\"post\", alpha=0.2, color=\"b\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlim([0.0, 1.05])\n",
    "    ax.set_title(\"Precision-Recall curve: AP={0:0.3f}\".format(metrics_AP))\n",
    "    \n",
    "    if axis is None:  # for standalone plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = df_data_pred[\"label\"].replace(\"fake\", 1).replace(\"real\", 0)\n",
    "y_pred = df_data_pred[\"label_pred\"].replace(\"fake\", 1).replace(\"real\", 0)\n",
    "\n",
    "plot_precision_recall_curve(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    y_real,\n",
    "    y_predict,\n",
    "    axis=None,\n",
    "    plot_style=\"ggplot\",\n",
    "):\n",
    "    \"\"\"Plot a nice ROC curve for a binary classification model\"\"\"\n",
    "\n",
    "    if axis is None:  # for standalone plot\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    else:  # for plots inside a subplot\n",
    "        ax = axis\n",
    "\n",
    "    plt.style.use(plot_style)\n",
    "\n",
    "    metrics_FPR, metrics_TPR, _ = metrics.roc_curve(y_real, y_predict)\n",
    "    metrics_AUC = metrics.roc_auc_score(y_real, y_predict)\n",
    "\n",
    "    ax.set_aspect(aspect=0.95)\n",
    "    ax.plot(metrics_FPR, metrics_TPR, color=\"b\", linewidth=0.7)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        metrics_FPR,\n",
    "        metrics_TPR,\n",
    "        step=\"post\",\n",
    "        alpha=0.2,\n",
    "        color=\"b\",\n",
    "    )\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC curve: AUC={0:0.3f}\".format(metrics_AUC))\n",
    "    \n",
    "    if axis is None:  # for standalone plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "To clear up your environment after running through this example and avoid ongoing charges, you can un-comment and run the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete Endpoint\n",
    "# print(\"Deleting endpoint...\")\n",
    "# endpoint_delete_response = client_comp.delete_endpoint(EndpointArn=endpoint_arn)\n",
    "# try: \n",
    "#     while client_comp.describe_endpoint(\n",
    "#         EndpointArn=endpoint_arn\n",
    "#     )[\"EndpointProperties\"][\"Status\"] == \"DELETING\":\n",
    "#         sleep(60)\n",
    "# except:\n",
    "#     pass\n",
    "# print(\"Endpoint Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete Classifier\n",
    "# classifier_delete_response = client_comp.delete_document_classifier(DocumentClassifierArn=doc_classifier_arn)\n",
    "# print(\"Classifier Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete S3 File\n",
    "# s3_delete_reponse = s3_client.delete_object(Bucket=bucket, Key=prefix+\"processed.csv\")\n",
    "# s3_delete_reponse_1 = s3_client.delete_object(Bucket=bucket, Key=prefix+\"test.txt\")\n",
    "# print(\n",
    "#     \"Data in S3 has been deleted. HTTP Code:\",\n",
    "#     s3_delete_reponse[\"ResponseMetadata\"][\"HTTPStatusCode\"],\n",
    "#     \",\",\n",
    "#     s3_delete_reponse_1[\"ResponseMetadata\"][\"HTTPStatusCode\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete IAM Role\n",
    "# try:\n",
    "#     role_detach_response = client_iam.detach_role_policy(\n",
    "#         RoleName=comprehend_role_name,\n",
    "#         PolicyArn=policy_arn,\n",
    "#     )\n",
    "#     print(\"Policy is detached\")\n",
    "# except:\n",
    "#     print(\"Policy could not be detached\")\n",
    "# role_delete_response = client_iam.delete_role(RoleName=comprehend_role_name)\n",
    "# print(\"Role is deleted\", role_delete_response)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
